{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc2d6c3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Requirement already satisfied: torch in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (0.24.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from torch) (2025.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from torchvision) (2.3.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from jinja2->torch) (3.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (2.3.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: open3d in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (3.10.7)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from tqdm) (0.4.6)\n",
      "Requirement already satisfied: dash>=2.6.0 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from open3d) (3.3.0)\n",
      "Requirement already satisfied: werkzeug>=3.0.0 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from open3d) (3.1.4)\n",
      "Requirement already satisfied: flask>=3.0.0 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from open3d) (3.1.2)\n",
      "Requirement already satisfied: nbformat>=5.7.0 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from open3d) (5.10.4)\n",
      "Requirement already satisfied: configargparse in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from open3d) (1.7.1)\n",
      "Requirement already satisfied: ipywidgets>=8.0.4 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from open3d) (8.1.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from matplotlib) (4.61.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: plotly>=5.0.0 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from dash>=2.6.0->open3d) (6.5.0)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from dash>=2.6.0->open3d) (8.7.0)\n",
      "Requirement already satisfied: typing_extensions>=4.1.1 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from dash>=2.6.0->open3d) (4.15.0)\n",
      "Requirement already satisfied: requests in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from dash>=2.6.0->open3d) (2.32.5)\n",
      "Requirement already satisfied: retrying in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from dash>=2.6.0->open3d) (1.4.2)\n",
      "Requirement already satisfied: nest-asyncio in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from dash>=2.6.0->open3d) (1.6.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from dash>=2.6.0->open3d) (80.9.0)\n",
      "Requirement already satisfied: blinker>=1.9.0 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from flask>=3.0.0->open3d) (1.9.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from flask>=3.0.0->open3d) (8.3.1)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from flask>=3.0.0->open3d) (2.2.0)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from flask>=3.0.0->open3d) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from flask>=3.0.0->open3d) (3.0.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (0.2.3)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (9.8.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.14 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (4.0.15)\n",
      "Requirement already satisfied: jupyterlab_widgets~=3.0.15 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from ipywidgets>=8.0.4->open3d) (3.0.16)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from nbformat>=5.7.0->open3d) (2.21.2)\n",
      "Requirement already satisfied: jsonschema>=2.6 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from nbformat>=5.7.0->open3d) (4.25.1)\n",
      "Requirement already satisfied: jupyter-core!=5.0.*,>=4.12 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from nbformat>=5.7.0->open3d) (5.9.1)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: decorator>=4.3.2 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (5.2.1)\n",
      "Requirement already satisfied: ipython-pygments-lexers>=1.0.0 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (1.1.1)\n",
      "Requirement already satisfied: jedi>=0.18.1 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline>=0.1.5 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.1)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.52)\n",
      "Requirement already satisfied: pygments>=2.11.0 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.19.2)\n",
      "Requirement already satisfied: stack_data>=0.6.0 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.6.3)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (25.4.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.37.0)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from jsonschema>=2.6->nbformat>=5.7.0->open3d) (0.30.0)\n",
      "Requirement already satisfied: platformdirs>=2.5 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from jupyter-core!=5.0.*,>=4.12->nbformat>=5.7.0->open3d) (4.5.1)\n",
      "Requirement already satisfied: narwhals>=1.15.1 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from plotly>=5.0.0->dash>=2.6.0->open3d) (2.13.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from importlib-metadata->dash>=2.6.0->open3d) (3.23.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from requests->dash>=2.6.0->open3d) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from requests->dash>=2.6.0->open3d) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from requests->dash>=2.6.0->open3d) (2.6.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from requests->dash>=2.6.0->open3d) (2025.11.12)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from jedi>=0.18.1->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.8.5)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.14)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (2.2.1)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (3.0.1)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\anast\\ml\\cvin3d\\labs\\lib\\site-packages (from stack_data>=0.6.0->ipython>=6.1.0->ipywidgets>=8.0.4->open3d) (0.2.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!{sys.executable} -m pip install numpy scikit-learn tqdm open3d matplotlib\n",
    "\n",
    "# –ò–º–ø–æ—Ä—Ç—ã\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import open3d as o3d\n",
    "from collections import defaultdict, Counter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e4c1f6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–í—Å–µ–≥–æ –∫–ª–∞—Å—Å–æ–≤: 14\n"
     ]
    }
   ],
   "source": [
    "# üîÅ –ó–ê–ú–ï–ù–ò–¢–ï –ù–ê –°–í–û–ô –ü–£–¢–¨!\n",
    "S3DIS_ROOT = \"C:/Users/anast/ml/CVin3D/lab4/task2/Stanford3dDataset\"  # ‚Üê –≤–∞—à –ø—É—Ç—å –∫ Area_1, Area_2 –∏ —Ç.–¥.\n",
    "OUTPUT_DIR = \"./output\"\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "CLASS_NAMES = [\n",
    "    'ceiling', 'floor', 'wall', 'beam', 'column',\n",
    "    'window', 'door', 'table', 'chair', 'sofa',\n",
    "    'bookcase', 'board', 'clutter', 'stairs'\n",
    "]\n",
    "NUM_CLASSES = len(CLASS_NAMES)\n",
    "print(f\"–í—Å–µ–≥–æ –∫–ª–∞—Å—Å–æ–≤: {NUM_CLASSES}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a51a5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_room_from_array(data: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"–í—Ö–æ–¥: (N, 7) ‚Üí x,y,z,r,g,b,label ‚Üí –≤—ã—Ö–æ–¥: (N, 6+1) –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω—ã–µ xyz+rgb+label\"\"\"\n",
    "    if data.shape[1] < 7:\n",
    "        raise ValueError(f\"–û–∂–∏–¥–∞–ª–æ—Å—å ‚â•7 —Å—Ç–æ–ª–±—Ü–æ–≤, –ø–æ–ª—É—á–µ–Ω–æ {data.shape[1]}\")\n",
    "    xyz = data[:, :3]\n",
    "    rgb = data[:, 3:6]\n",
    "    labels = data[:, 6].astype(np.int64)\n",
    "\n",
    "    rgb = np.clip(rgb / 255.0, 0.0, 1.0)\n",
    "    xyz -= np.mean(xyz, axis=0)\n",
    "    scale = np.max(np.abs(xyz)) + 1e-8\n",
    "    xyz /= scale\n",
    "\n",
    "    return np.hstack([xyz, rgb, labels.reshape(-1, 1)])\n",
    "\n",
    "\n",
    "def process_area_with_meta(area_dir: str, area_id: int) -> np.ndarray:\n",
    "    \"\"\"–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –º–∞—Å—Å–∏–≤ (N, 9): x,y,z,r,g,b,label,area_id,room_id_hash\"\"\"\n",
    "    all_points = []\n",
    "    \n",
    "    for room_name in sorted(os.listdir(area_dir)):\n",
    "        room_path = os.path.join(area_dir, room_name)\n",
    "        if not os.path.isdir(room_path):\n",
    "            continue\n",
    "\n",
    "        ann_path = os.path.join(room_path, 'Annotations')\n",
    "        room_data = []\n",
    "        if os.path.isdir(ann_path):\n",
    "            obj_files = [f for f in os.listdir(ann_path) if f.endswith('.txt')]\n",
    "            for obj_file in obj_files:\n",
    "                obj_full = os.path.join(ann_path, obj_file)\n",
    "                obj_name = os.path.splitext(obj_file)[0].split('_')[0]\n",
    "                try:\n",
    "                    label_id = CLASS_NAMES.index(obj_name)\n",
    "                except ValueError:\n",
    "                    # print(f\"‚ö†Ô∏è –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∫–ª–∞—Å—Å: {obj_name}\")\n",
    "                    continue\n",
    "                try:\n",
    "                    obj_pts = np.genfromtxt(obj_full, delimiter=' ', dtype=np.float32)\n",
    "                    if obj_pts.ndim == 1:\n",
    "                        obj_pts = obj_pts.reshape(1, -1)\n",
    "                    if obj_pts.shape[1] == 6:\n",
    "                        obj_pts = np.hstack([obj_pts, np.full((obj_pts.shape[0], 1), label_id)])\n",
    "                    elif obj_pts.shape[1] >= 7:\n",
    "                        obj_pts = obj_pts[:, :7]  # –±–µ—Ä—ë–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 7\n",
    "                        obj_pts[:, 6] = label_id\n",
    "                    room_data.append(obj_pts)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå –û—à–∏–±–∫–∞ {obj_full}: {e}\")\n",
    "                    continue\n",
    "\n",
    "            if room_data:\n",
    "                room_points = np.vstack(room_data)\n",
    "                room_processed = process_room_from_array(room_points)\n",
    "                # –î–æ–±–∞–≤–ª—è–µ–º meta: area_id, room_hash\n",
    "                room_hash = abs(hash(room_name)) % 100000\n",
    "                meta = np.full((room_processed.shape[0], 2), [area_id, room_hash])\n",
    "                room_with_meta = np.hstack([room_processed, meta])\n",
    "                all_points.append(room_with_meta)\n",
    "        else:\n",
    "            # –ï—Å–ª–∏ –Ω–µ—Ç Annotations ‚Äî –∏—â–µ–º room*.txt\n",
    "            room_txts = [f for f in os.listdir(room_path) if f.startswith('room') and f.endswith('.txt')]\n",
    "            for txt in room_txts:\n",
    "                full_txt = os.path.join(room_path, txt)\n",
    "                try:\n",
    "                    data_raw = np.genfromtxt(full_txt, delimiter=' ', dtype=np.float32)\n",
    "                    if data_raw.shape[1] >= 7:\n",
    "                        data_proc = process_room_from_array(data_raw[:, :7])\n",
    "                        room_hash = abs(hash(txt)) % 100000\n",
    "                        meta = np.full((data_proc.shape[0], 2), [area_id, room_hash])\n",
    "                        all_points.append(np.hstack([data_proc, meta]))\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ {full_txt}: {e}\")\n",
    "\n",
    "    if not all_points:\n",
    "        print(f\"‚ö†Ô∏è Area_{area_id}: –Ω–µ—Ç –¥–∞–Ω–Ω—ã—Ö\")\n",
    "        return np.empty((0, 9), dtype=np.float32)\n",
    "\n",
    "    return np.vstack(all_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "456385f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é Area_1...\n",
      "‚ùå –û—à–∏–±–∫–∞ C:/Users/anast/ml/CVin3D/lab4/task2/Stanford3dDataset\\Area_1\\office_22\\Annotations\\clutter_16.txt: Unable to allocate 1.08 MiB for an array with shape (20171, 7) and data type float64\n",
      " MemoryError –≤ Area_1: Unable to allocate 45.7 MiB for an array with shape (856367, 7) and data type float64\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 45.7 MiB for an array with shape (856367, 7) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é Area_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     area_data = \u001b[43mprocess_area_with_meta\u001b[49m\u001b[43m(\u001b[49m\u001b[43marea_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marea_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (N, 9), float64\u001b[39;00m\n\u001b[32m     12\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m  ‚Üí \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marea_data.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m —Ç–æ—á–µ–∫, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marea_data.dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     14\u001b[39m     area_data = area_data.astype(np.float32)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 53\u001b[39m, in \u001b[36mprocess_area_with_meta\u001b[39m\u001b[34m(area_dir, area_id)\u001b[39m\n\u001b[32m     50\u001b[39m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     52\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m room_data:\n\u001b[32m---> \u001b[39m\u001b[32m53\u001b[39m     room_points = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mroom_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     54\u001b[39m     room_processed = process_room_from_array(room_points)\n\u001b[32m     55\u001b[39m     \u001b[38;5;66;03m# –î–æ–±–∞–≤–ª—è–µ–º meta: area_id, room_hash\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anast\\ml\\CVin3D\\labs\\Lib\\site-packages\\numpy\\_core\\shape_base.py:292\u001b[39m, in \u001b[36mvstack\u001b[39m\u001b[34m(tup, dtype, casting)\u001b[39m\n\u001b[32m    290\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arrs, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    291\u001b[39m     arrs = (arrs,)\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_nx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcasting\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcasting\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 45.7 MiB for an array with shape (856367, 7) and data type float64"
     ]
    }
   ],
   "source": [
    "area_files = []\n",
    "\n",
    "for i in range(1, 7):\n",
    "    area_path = os.path.join(S3DIS_ROOT, f\"Area_{i}\")\n",
    "    if not os.path.isdir(area_path):\n",
    "        print(f\" –ü—Ä–æ–ø—É—â–µ–Ω Area_{i}: –ø–∞–ø–∫–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞\")\n",
    "        continue\n",
    "\n",
    "    print(f\"–û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é Area_{i}...\")\n",
    "    try:\n",
    "        area_data = process_area_with_meta(area_path, area_id=i)  # (N, 9), float64\n",
    "        print(f\"  ‚Üí {area_data.shape[0]:,} —Ç–æ—á–µ–∫, {area_data.dtype}\")\n",
    "        \n",
    "        area_data = area_data.astype(np.float32)\n",
    "        area_file = os.path.join(OUTPUT_DIR, f\"area_{i}.npy\")\n",
    "        np.save(area_file, area_data)\n",
    "        area_files.append(area_file)\n",
    "        print(f\"   –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {area_file} | {os.path.getsize(area_file) / 1e6:.1f} MB\")\n",
    "        \n",
    "        del area_data\n",
    "    except MemoryError as e:\n",
    "        print(f\" MemoryError –≤ Area_{i}: {e}\")\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        print(f\" –û—à–∏–±–∫–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ Area_{i}: {e}\")\n",
    "        continue\n",
    "\n",
    "print(f\"\\n –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(area_files)} Area.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "44ccc8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_room_txt(file_path):\n",
    "    \"\"\"–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∫–æ–º–Ω–∞—Ç—É –∏–∑ .txt, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç (N, 7): xyzrgb + class_id\"\"\"\n",
    "    data = np.loadtxt(file_path)  # (N, 7)\n",
    "    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º —Ü–≤–µ—Ç –≤ [0,1]\n",
    "    data[:, 3:6] = data[:, 3:6] / 255.0\n",
    "    return data.astype(np.float32)  # —ç–∫–æ–Ω–æ–º–∏–º –ø–∞–º—è—Ç—å: float32!\n",
    "\n",
    "def room_to_blocks(data, block_size=1.5, stride=1.0, max_points=4096, min_points=1024):\n",
    "    \"\"\"–†–µ–∂–µ—Ç –æ–±–ª–∞–∫–æ –Ω–∞ –±–ª–æ–∫–∏ —Ñ–∏–∫—Å. —Ä–∞–∑–º–µ—Ä–∞ (–≤ –º–µ—Ç—Ä–∞—Ö), –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–ø–∏—Å–æ–∫ –±–ª–æ–∫–æ–≤\"\"\"\n",
    "    blocks = []\n",
    "    labels = []\n",
    "\n",
    "    xyz = data[:, :3]\n",
    "    mins = np.min(xyz, axis=0)\n",
    "    maxs = np.max(xyz, axis=0)\n",
    "\n",
    "    # –°–µ—Ç–∫–∞ –±–ª–æ–∫–æ–≤ –ø–æ X –∏ Y (Z ‚Äî –≤—Å—è –≤—ã—Å–æ—Ç–∞ –∫–æ–º–Ω–∞—Ç—ã)\n",
    "    x_starts = np.arange(mins[0], maxs[0], stride)\n",
    "    y_starts = np.arange(mins[1], maxs[1], stride)\n",
    "\n",
    "    for x in x_starts:\n",
    "        for y in y_starts:\n",
    "            x_mask = (xyz[:, 0] >= x) & (xyz[:, 0] < x + block_size)\n",
    "            y_mask = (xyz[:, 1] >= y) & (xyz[:, 1] < y + block_size)\n",
    "            mask = x_mask & y_mask\n",
    "            block = data[mask]\n",
    "            if len(block) < min_points:\n",
    "                continue\n",
    "            # –°—ç–º–ø–ª–∏—Ä—É–µ–º –¥–æ max_points\n",
    "            if len(block) > max_points:\n",
    "                idx = np.random.choice(len(block), max_points, replace=False)\n",
    "                block = block[idx]\n",
    "            else:\n",
    "                # –¥–æ–ø–æ–ª–Ω—è–µ–º –¥–æ max_points (—Ä–µ–∂–µ, –Ω–æ –±–µ–∑–æ–ø–∞—Å–Ω–æ)\n",
    "                idx = np.random.choice(len(block), max_points, replace=True)\n",
    "                block = block[idx]\n",
    "            blocks.append(block[:, :6])   # xyzrgb\n",
    "            labels.append(block[:, 6].astype(np.int64))  # class\n",
    "\n",
    "    return blocks, labels\n",
    "\n",
    "class S3DISBlockDataset(Dataset):\n",
    "    def __init__(self, area_path, room_limit=None, block_size=1.5, max_points=4096):\n",
    "        self.blocks = []\n",
    "        self.labels = []\n",
    "        room_dirs = sorted([d for d in os.listdir(area_path) if os.path.isdir(os.path.join(area_path, d))])\n",
    "        \n",
    "        if room_limit:\n",
    "            room_dirs = room_dirs[:room_limit]  # ‚ö†Ô∏è –û–ì–†–ê–ù–ò–ß–ò–í–ê–ï–ú –ß–ò–°–õ–û –ö–û–ú–ù–ê–¢!\n",
    "        \n",
    "        print(f\"–ó–∞–≥—Ä—É–∑–∫–∞ {len(room_dirs)} –∫–æ–º–Ω–∞—Ç –∏–∑ {area_path}...\")\n",
    "        for room in room_dirs:\n",
    "            room_path = os.path.join(area_path, room, \"Annotations\")\n",
    "            if not os.path.exists(room_path):\n",
    "                continue\n",
    "            # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ –æ–±—ä–µ–∫—Ç—ã –∫–æ–º–Ω–∞—Ç—ã (—Å—Ç–µ–Ω—ã, –ø–æ–ª –∏ —Ç.–¥.)\n",
    "            obj_files = [f for f in os.listdir(room_path) if f.endswith('.txt')]\n",
    "            room_data = []\n",
    "            for obj_file in obj_files:\n",
    "                obj_path = os.path.join(room_path, obj_file)\n",
    "                try:\n",
    "                    obj_data = np.loadtxt(obj_path)\n",
    "                    # –î–æ–±–∞–≤–ª—è–µ–º class_id –∏–∑ –∏–º–µ–Ω–∏ —Ñ–∞–π–ª–∞, –Ω–∞–ø—Ä–∏–º–µ—Ä: \"wall_1.txt\" ‚Üí class 2\n",
    "                    cls_name = obj_file.split('_')[0].lower()\n",
    "                    # –ü—Ä–æ—Å—Ç–æ–µ –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏–µ (–¥–ª—è –¥–µ–º–æ ‚Äî 13 –∫–ª–∞—Å—Å–æ–≤ –Ω–µ –∫—Ä–∏—Ç–∏—á–Ω–æ):\n",
    "                    class_map = {'ceiling':0, 'floor':1, 'wall':2, 'beam':3, 'column':4,\n",
    "                                 'window':5, 'door':6, 'table':7, 'chair':8, 'sofa':9,\n",
    "                                 'bookcase':10, 'board':11, 'clutter':12}\n",
    "                    cls_id = class_map.get(cls_name, 12)\n",
    "                    obj_data = np.column_stack([obj_data, np.full(len(obj_data), cls_id)])\n",
    "                    room_data.append(obj_data)\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è –ü—Ä–æ–ø—É—â–µ–Ω —Ñ–∞–π–ª {obj_file}: {e}\")\n",
    "                    continue\n",
    "            if not room_data:\n",
    "                continue\n",
    "            room_data = np.vstack(room_data).astype(np.float32)\n",
    "            # –†–µ–∂–µ–º –Ω–∞ –±–ª–æ–∫–∏\n",
    "            blocks, labels = room_to_blocks(room_data, block_size=block_size, max_points=max_points)\n",
    "            self.blocks.extend(blocks)\n",
    "            self.labels.extend(labels)\n",
    "            if len(self.blocks) > 500:  # ‚ö†Ô∏è –û–ì–†–ê–ù–ò–ß–ò–í–ê–ï–ú –ß–ò–°–õ–û –ë–õ–û–ö–û–í!\n",
    "                break\n",
    "\n",
    "        print(f\"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(self.blocks)} –±–ª–æ–∫–æ–≤.\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.blocks)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        points = torch.from_numpy(self.blocks[idx])\n",
    "        labels = torch.from_numpy(self.labels[idx])\n",
    "        return points, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71813332",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_points = 0\n",
    "for f in area_files:\n",
    "    with open(f, \"rb\") as fh:\n",
    "        import numpy.lib.format as npfmt\n",
    "        version = npfmt.read_magic(fh)\n",
    "        header = npfmt._read_array_header(fh, version)\n",
    "        shape = header[1]\n",
    "        total_points += shape[0]\n",
    "\n",
    "print(f\"–û–±—â–µ–µ —á–∏—Å–ª–æ —Ç–æ—á–µ–∫: {total_points:,}\")\n",
    "\n",
    "NPY_PATH = os.path.join(OUTPUT_DIR, \"s3dis_full.npy\")\n",
    "with open(NPY_PATH, \"wb\") as f_out:\n",
    "    import struct\n",
    "    import numpy as np\n",
    "\n",
    "    header_dict = {\n",
    "        'descr': '<f4',  # float32, little-endian\n",
    "        'fortran_order': False,\n",
    "        'shape': (total_points, 9)\n",
    "    }\n",
    "    header_str = f\"{{'descr': '{header_dict['descr']}', 'fortran_order': {header_dict['fortran_order']}, 'shape': {header_dict['shape']}, }}\"\n",
    "    header_len = len(header_str) + 1  # +1 for \\n\n",
    "    padding = (64 - (10 + header_len) % 64) % 64\n",
    "    header = f\"\\x93NUMPY\\x01\\x00{''.ljust(2, '\\x00')}\" \\\n",
    "             + struct.pack('<H', header_len + padding) \\\n",
    "             + header_str + ' ' * padding + '\\n'\n",
    "\n",
    "    f_out.write(header.encode('latin1'))\n",
    "\n",
    "    written = 0\n",
    "    for f_path in area_files:\n",
    "        print(f\"–î–æ–±–∞–≤–ª—è—é {os.path.basename(f_path)}...\")\n",
    "        arr = np.load(f_path, mmap_mode='r')  \n",
    "        arr.tofile(f_out)\n",
    "        written += arr.shape[0]\n",
    "        del arr  \n",
    "\n",
    "print(f\" –ò—Ç–æ–≥–æ–≤—ã–π —Ñ–∞–π–ª —Å–æ–∑–¥–∞–Ω: {NPY_PATH}\")\n",
    "print(f\"   –†–∞–∑–º–µ—Ä: {os.path.getsize(NPY_PATH) / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80b987d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "–ó–∞–≥—Ä—É–∑–∫–∞ 2 –∫–æ–º–Ω–∞—Ç –∏–∑ C:/Users/anast/ml/CVin3D/lab4/task2/Stanford3dDataset\\Area_1...\n",
      "‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ 62 –±–ª–æ–∫–æ–≤.\n",
      "–†–∞–∑–º–µ—Ä –±–ª–æ–∫–∞: torch.Size([4096, 6])\n"
     ]
    }
   ],
   "source": [
    "# üîÅ –£–∫–∞–∂–∏ –ü–†–ê–í–ò–õ–¨–ù–´–ô –ø—É—Ç—å –∫ S3DIS!\n",
    "S3DIS_ROOT = \"C:/Users/anast/ml/CVin3D/lab4/task2/Stanford3dDataset\"  # ‚Üê –ó–ê–ú–ï–ù–ò –ù–ê –°–í–û–ô!\n",
    "\n",
    "area1_path = os.path.join(S3DIS_ROOT, \"Area_1\")\n",
    "\n",
    "# –ó–∞–≥—Ä—É–∂–∞–µ–º –¢–û–õ–¨–ö–û 2 –∫–æ–º–Ω–∞—Ç—ã, –Ω–µ –±–æ–ª–µ–µ 200 –±–ª–æ–∫–æ–≤\n",
    "try:\n",
    "    dataset = S3DISBlockDataset(area1_path, room_limit=2)  # ‚¨ÖÔ∏è –ö–õ–Æ–ß: room_limit=2\n",
    "except Exception as e:\n",
    "    print(\"‚ùå –û—à–∏–±–∫–∞:\", e)\n",
    "    print(\"\\n‚ùó –ï—Å–ª–∏ –ø—É—Ç—å –Ω–µ–≤–µ—Ä–Ω—ã–π ‚Äî –∑–∞–≥—Ä—É–∑–∏–º –¥–µ–º–æ-–¥–∞–Ω–Ω—ã–µ (–∏–∑ –ø–∞–º—è—Ç–∏)...\")\n",
    "    # fallback: –≥–µ–Ω–µ—Ä–∞—Ü–∏—è 50 –±–ª–æ–∫–æ–≤ –∏–≥—Ä—É—à–µ—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–∫–∞–∫ –≤ –ø—Ä–æ—à–ª–æ–º –æ—Ç–≤–µ—Ç–µ)\n",
    "    from sklearn.datasets import make_blobs\n",
    "    blocks, labels = [], []\n",
    "    for _ in range(50):\n",
    "        pts, lbls = generate_room_points(num_points=4096)\n",
    "        blocks.append(pts)\n",
    "        labels.append(lbls)\n",
    "    dataset = ToyPointCloudDataset(np.stack(blocks), np.stack(labels))\n",
    "\n",
    "print(\"–†–∞–∑–º–µ—Ä –±–ª–æ–∫–∞:\", dataset[0][0].shape)  # –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å (4096, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bf424f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# --- –í—Å–ø–æ–º–æ–≥–∞—Ç–µ–ª—å–Ω—ã–µ —Ñ—É–Ω–∫—Ü–∏–∏ (–±–µ–∑ –∏–∑–º–µ–Ω–µ–Ω–∏–π, —Ä–∞–±–æ—Ç–∞—é—Ç) ---\n",
    "def square_distance(src, dst):\n",
    "    return torch.sum((src[:, :, None, :] - dst[:, None, :, :]) ** 2, dim=-1)\n",
    "\n",
    "def farthest_point_sample(xyz, npoint):\n",
    "    device = xyz.device\n",
    "    B, N, _ = xyz.shape\n",
    "    centroids = torch.zeros(B, npoint, dtype=torch.long, device=device)\n",
    "    distance = torch.ones(B, N, device=device) * 1e10\n",
    "    farthest = torch.randint(0, N, (B,), dtype=torch.long, device=device)\n",
    "    batch_indices = torch.arange(B, dtype=torch.long, device=device)\n",
    "    for i in range(npoint):\n",
    "        centroids[:, i] = farthest\n",
    "        centroid = xyz[batch_indices, farthest].view(B, 1, 3)\n",
    "        dist = torch.sum((xyz - centroid) ** 2, -1)\n",
    "        mask = dist < distance\n",
    "        distance[mask] = dist[mask]\n",
    "        farthest = torch.max(distance, -1)[1]\n",
    "    return centroids\n",
    "\n",
    "def index_points(points, idx):\n",
    "    raw_shape = idx.shape\n",
    "    idx = idx.reshape(raw_shape[0], -1)\n",
    "    res = torch.gather(points, 1, idx.unsqueeze(-1).expand(-1, -1, points.size(-1)))\n",
    "    return res.reshape(*raw_shape, -1)\n",
    "\n",
    "def query_ball_point(radius, nsample, xyz, new_xyz):\n",
    "    device = xyz.device\n",
    "    B, N, _ = xyz.shape\n",
    "    S = new_xyz.shape[1]\n",
    "    K = nsample\n",
    "    group_idx = torch.arange(N, dtype=torch.long, device=device).view(1, 1, N).repeat(B, S, 1)\n",
    "    sqrdists = square_distance(new_xyz, xyz)\n",
    "    group_idx[sqrdists > radius ** 2] = N\n",
    "    group_idx = group_idx.sort(dim=-1)[0][:, :, :K]\n",
    "    group_first = group_idx[:, :, 0].view(B, S, 1).repeat(1, 1, K)\n",
    "    mask = group_idx == N\n",
    "    group_idx[mask] = group_first[mask]\n",
    "    return group_idx\n",
    "\n",
    "# --- –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–π Set Abstraction (—Ä–∞–±–æ—Ç–∞–µ—Ç –∏ —Å points=None, –∏ —Å points) ---\n",
    "class PointNetSetAbstraction(nn.Module):\n",
    "    def __init__(self, npoint, radius, nsample, in_channel, mlp):\n",
    "        super().__init__()\n",
    "        self.npoint = npoint\n",
    "        self.radius = radius\n",
    "        self.nsample = nsample\n",
    "        self.mlp_convs = nn.ModuleList()\n",
    "        self.mlp_bns = nn.ModuleList()\n",
    "        \n",
    "        # –í–ê–ñ–ù–û: –æ–∂–∏–¥–∞–µ–º—ã–π –≤—Ö–æ–¥ ‚Äî (C_local + 3), –≥–¥–µ C_local = in_channel (rgb/feat), 3 = dxyz\n",
    "        last_channel = in_channel + 3\n",
    "        for out_channel in mlp:\n",
    "            self.mlp_convs.append(nn.Conv2d(last_channel, out_channel, 1))\n",
    "            self.mlp_bns.append(nn.BatchNorm2d(out_channel))\n",
    "            last_channel = out_channel\n",
    "\n",
    "    def forward(self, xyz, points):\n",
    "        \"\"\"\n",
    "        xyz: (B, N, 3)\n",
    "        points: (B, N, C) ‚Äî –º–æ–∂–µ—Ç –±—ã—Ç—å None (—Ç–æ–≥–¥–∞ C=0), –Ω–æ –ª—É—á—à–µ –ø–µ—Ä–µ–¥–∞–≤–∞—Ç—å —Ö–æ—Ç—è –±—ã rgb\n",
    "        \"\"\"\n",
    "        B, N, _ = xyz.shape\n",
    "        S = self.npoint\n",
    "\n",
    "        fps_idx = farthest_point_sample(xyz, S)   # (B, S)\n",
    "        new_xyz = index_points(xyz, fps_idx)      # (B, S, 3)\n",
    "        idx = query_ball_point(self.radius, self.nsample, xyz, new_xyz)  # (B, S, K)\n",
    "        grouped_xyz = index_points(xyz, idx)      # (B, S, K, 3)\n",
    "        grouped_xyz_norm = grouped_xyz - new_xyz.view(B, S, 1, 3)  # (B, S, K, 3)\n",
    "\n",
    "        if points is not None:\n",
    "            grouped_points = index_points(points, idx)     # (B, S, K, C)\n",
    "            new_points = torch.cat([grouped_xyz_norm, grouped_points], dim=-1)  # (B, S, K, C+3)\n",
    "        else:\n",
    "            new_points = grouped_xyz_norm  # (B, S, K, 3) ‚Üí —Ç–æ–≥–¥–∞ in_channel –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 0!\n",
    "\n",
    "        new_points = new_points.permute(0, 3, 2, 1)  # (B, C+3, K, S)\n",
    "        for i, conv in enumerate(self.mlp_convs):\n",
    "            bn = self.mlp_bns[i]\n",
    "            new_points = F.relu(bn(conv(new_points)))\n",
    "        new_points = torch.max(new_points, 2)[0]  # (B, C_out, S)\n",
    "        new_points = new_points.permute(0, 2, 1)  # (B, S, C_out)\n",
    "        return new_xyz, new_points\n",
    "\n",
    "class PointNetFeaturePropagation(nn.Module):\n",
    "    def __init__(self, in_channel, mlp):\n",
    "        super().__init__()\n",
    "        self.mlp_convs = nn.ModuleList()\n",
    "        self.mlp_bns = nn.ModuleList()\n",
    "        last_channel = in_channel\n",
    "        for out_channel in mlp:\n",
    "            self.mlp_convs.append(nn.Conv1d(last_channel, out_channel, 1))\n",
    "            self.mlp_bns.append(nn.BatchNorm1d(out_channel))\n",
    "            last_channel = out_channel\n",
    "\n",
    "    def forward(self, xyz1, xyz2, points1, points2):\n",
    "        B, N, _ = xyz1.shape\n",
    "        _, S, _ = xyz2.shape\n",
    "\n",
    "        if S == 1:\n",
    "            interpolated_points = points2.repeat(1, N, 1)\n",
    "        else:\n",
    "            dists = square_distance(xyz1, xyz2)\n",
    "            dists, idx = dists.sort(dim=-1)\n",
    "            dists, idx = dists[:, :, :3], idx[:, :, :3]\n",
    "            dist_recip = 1.0 / (dists + 1e-8)\n",
    "            norm = torch.sum(dist_recip, dim=2, keepdim=True)\n",
    "            weight = dist_recip / norm\n",
    "            interpolated_points = torch.sum(index_points(points2, idx) * weight.unsqueeze(-1), dim=2)\n",
    "\n",
    "        if points1 is not None:\n",
    "            new_points = torch.cat([points1, interpolated_points], dim=-1)\n",
    "        else:\n",
    "            new_points = interpolated_points\n",
    "\n",
    "        new_points = new_points.permute(0, 2, 1)\n",
    "        for i, conv in enumerate(self.mlp_convs):\n",
    "            bn = self.mlp_bns[i]\n",
    "            new_points = F.relu(bn(conv(new_points)))\n",
    "        return new_points.permute(0, 2, 1)\n",
    "\n",
    "# ‚úÖ –§–ò–ù–ê–õ–¨–ù–ê–Ø –†–ê–ë–û–ß–ê–Ø –ú–û–î–ï–õ–¨\n",
    "class MiniPointNet2Seg(nn.Module):\n",
    "    def __init__(self, num_classes=13):\n",
    "        super().__init__()\n",
    "        # –ü–µ—Ä–≤—ã–π —É—Ä–æ–≤–µ–Ω—å: –≤—Ö–æ–¥ ‚Äî xyz (3) + rgb (3) = 6 ‚Üí –ø–æ—ç—Ç–æ–º—É in_channel=3 (rgb), +3 (dxyz) = 6\n",
    "        self.sa1 = PointNetSetAbstraction(\n",
    "            npoint=512,\n",
    "            radius=0.2,\n",
    "            nsample=32,\n",
    "            in_channel=3,   # ‚Üê —ç—Ç–æ rgb (–∏–ª–∏ –ª—é–±—ã–µ –ª–æ–∫–∞–ª—å–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏, –∫—Ä–æ–º–µ xyz)\n",
    "            mlp=[32, 64]\n",
    "        )\n",
    "        self.fp1 = PointNetFeaturePropagation(in_channel=64 + 3, mlp=[128, 128])  # 64 (sa1) + 3 (rgb)\n",
    "        self.conv1 = nn.Conv1d(128, 128, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.drop1 = nn.Dropout(0.5)\n",
    "        self.conv2 = nn.Conv1d(128, num_classes, 1)\n",
    "\n",
    "    def forward(self, xyzrgb):\n",
    "        # xyzrgb: (B, N, 6)\n",
    "        B, N, _ = xyzrgb.shape\n",
    "        xyz = xyzrgb[:, :, :3]    # (B, N, 3)\n",
    "        rgb = xyzrgb[:, :, 3:]    # (B, N, 3) ‚Üê –ø–µ—Ä–µ–¥–∞—ë–º –∫–∞–∫ points!\n",
    "\n",
    "        # SA: xyz + rgb ‚Üí –ø—Ä–∏–∑–Ω–∞–∫–∏\n",
    "        new_xyz, feat = self.sa1(xyz, rgb)  # feat: (B, 512, 64)\n",
    "\n",
    "        # FP: upsample –¥–æ N, –∏—Å–ø–æ–ª—å–∑—É–µ–º rgb –∫–∞–∫ –ª–æ–∫–∞–ª—å–Ω—ã–π –ø—Ä–∏–∑–Ω–∞–∫ –Ω–∞ –≤—Ö–æ–¥–µ\n",
    "        feat_up = self.fp1(xyz, new_xyz, rgb, feat)  # (B, N, 128)\n",
    "\n",
    "        # Seg head\n",
    "        x = feat_up.permute(0, 2, 1)  # (B, 128, N)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.drop1(x)\n",
    "        x = self.conv2(x)  # (B, C, N)\n",
    "        return x.permute(0, 2, 1)  # (B, N, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16dfc1b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –§–æ—Ä–º–∞ –≤—ã—Ö–æ–¥–∞: torch.Size([2, 4096, 13])\n"
     ]
    }
   ],
   "source": [
    "# –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ñ–æ—Ä–º—ã\n",
    "device = torch.device(\"cpu\")\n",
    "model = MiniPointNet2Seg(num_classes=13).to(device)\n",
    "dummy_input = torch.randn(2, 4096, 6)  # batch=2, N=4096, xyzrgb\n",
    "with torch.no_grad():\n",
    "    out = model(dummy_input)\n",
    "print(\" –§–æ—Ä–º–∞ –≤—ã—Ö–æ–¥–∞:\", out.shape)  # –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å: torch.Size([2, 4096, 13])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0978c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è (–±–µ–∑ .view ‚Äî —Ç–æ–ª—å–∫–æ .reshape)...\n",
      "Epoch 1 | Avg Loss (3 steps): 2.4620\n",
      "Epoch 2 | Avg Loss (3 steps): 1.9567\n",
      "üî• –£–°–ü–ï–•! –ú–æ–¥–µ–ª—å –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ CPU.\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cpu\")\n",
    "model = MiniPointNet2Seg(num_classes=13).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "print(\" –ó–∞–ø—É—Å–∫ –æ–±—É—á–µ–Ω–∏—è (–±–µ–∑ .view ‚Äî —Ç–æ–ª—å–∫–æ .reshape)...\")\n",
    "model.train()\n",
    "for epoch in range(1, 3):\n",
    "    total_loss = 0.0\n",
    "    for i, (points, labels) in enumerate(train_loader):\n",
    "        points, labels = points.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        out = model(points)  # (B, N, 13)\n",
    "        \n",
    "        # üîë –ö–õ–Æ–ß–ï–í–û–ï –ò–ó–ú–ï–ù–ï–ù–ò–ï: .reshape –≤–º–µ—Å—Ç–æ .view\n",
    "        loss = criterion(out.reshape(-1, 13), labels.reshape(-1))\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "        \n",
    "        if i == 2:  # 3 —à–∞–≥–∞ ‚Äî –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\n",
    "            break\n",
    "    \n",
    "    print(f\"Epoch {epoch} | Avg Loss (3 steps): {total_loss / 3:.4f}\")\n",
    "\n",
    "print(\"üî• –£–°–ü–ï–•! –ú–æ–¥–µ–ª—å –æ–±—É—á–∞–µ—Ç—Å—è –Ω–∞ CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfde8c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class S3DISAreaSplitDataset(Dataset):\n",
    "    def __init__(self, npy_path, split='train', num_points=4096, augment=True):\n",
    "        self.data = np.load(npy_path)  # (N, 9)\n",
    "        self.num_points = num_points\n",
    "        self.augment = augment and (split == 'train')\n",
    "        \n",
    "        area_ids = self.data[:, 7].astype(int)\n",
    "        if split == 'train':\n",
    "            mask = area_ids <= 5  \n",
    "        elif split == 'val':\n",
    "            mask = area_ids == 5  \n",
    "        elif split == 'test':\n",
    "            mask = area_ids == 6  \n",
    "        else:\n",
    "            raise ValueError(\"split = 'train'/'val'/'test'\")\n",
    "        \n",
    "        self.points = self.data[mask][:, :7]  # x,y,z,r,g,b,label\n",
    "        print(f\"{split.capitalize()}: {self.points.shape[0]:,} —Ç–æ—á–µ–∫\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return 1000\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        N = self.points.shape[0]\n",
    "        choice = np.random.choice(N, self.num_points, replace=N < self.num_points)\n",
    "        batch = self.points[choice]  \n",
    "\n",
    "        xyz = batch[:, :3].copy()\n",
    "        rgb = batch[:, 3:6].copy()\n",
    "        label = batch[:, 6].astype(np.int64)\n",
    "\n",
    "        if self.augment:\n",
    "            angle = np.random.uniform(0, 2 * np.pi)\n",
    "            cos_a, sin_a = np.cos(angle), np.sin(angle)\n",
    "            rot = np.array([[cos_a, -sin_a, 0],\n",
    "                            [sin_a,  cos_a, 0],\n",
    "                            [0,      0,     1]])\n",
    "            xyz = xyz @ rot\n",
    "            xyz += np.clip(0.01 * np.random.randn(*xyz.shape), -0.05, 0.05)\n",
    "\n",
    "        xyz -= np.mean(xyz, axis=0)\n",
    "        scale = np.max(np.linalg.norm(xyz, axis=1)) + 1e-8\n",
    "        xyz /= scale\n",
    "\n",
    "        pts = np.concatenate([xyz, rgb], axis=1).astype(np.float32)  # (P, 6)\n",
    "        return torch.from_numpy(pts), torch.from_numpy(label).long()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e349f08",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 18.3 GiB for an array with shape (2461918383,) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m BATCH_SIZE = \u001b[32m2\u001b[39m      \n\u001b[32m      5\u001b[39m NUM_WORKERS = \u001b[32m0\u001b[39m     \n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m train_ds = \u001b[43mS3DISAreaSplitDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNPY_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_points\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNUM_POINTS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m val_ds = S3DISAreaSplitDataset(NPY_PATH, split=\u001b[33m'\u001b[39m\u001b[33mval\u001b[39m\u001b[33m'\u001b[39m, num_points=NUM_POINTS)\n\u001b[32m      9\u001b[39m test_ds = S3DISAreaSplitDataset(NPY_PATH, split=\u001b[33m'\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m'\u001b[39m, num_points=NUM_POINTS)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mS3DISAreaSplitDataset.__init__\u001b[39m\u001b[34m(self, npy_path, split, num_points, augment)\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, npy_path, split=\u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m, num_points=\u001b[32m4096\u001b[39m, augment=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     \u001b[38;5;28mself\u001b[39m.data = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnpy_path\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# (N, 9)\u001b[39;00m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mself\u001b[39m.num_points = num_points\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mself\u001b[39m.augment = augment \u001b[38;5;129;01mand\u001b[39;00m (split == \u001b[33m'\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anast\\ml\\CVin3D\\labs\\Lib\\site-packages\\numpy\\lib\\_npyio_impl.py:483\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[39m\n\u001b[32m    480\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mformat\u001b[39m.open_memmap(file, mode=mmap_mode,\n\u001b[32m    481\u001b[39m                                   max_header_size=max_header_size)\n\u001b[32m    482\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m483\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_pickle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    484\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpickle_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    485\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_header_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    486\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    487\u001b[39m     \u001b[38;5;66;03m# Try a pickle\u001b[39;00m\n\u001b[32m    488\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_pickle:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\anast\\ml\\CVin3D\\labs\\Lib\\site-packages\\numpy\\lib\\_format_impl.py:847\u001b[39m, in \u001b[36mread_array\u001b[39m\u001b[34m(fp, allow_pickle, pickle_kwargs, max_header_size)\u001b[39m\n\u001b[32m    844\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    845\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m isfileobj(fp):\n\u001b[32m    846\u001b[39m         \u001b[38;5;66;03m# We can use the fast fromfile() function.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m847\u001b[39m         array = \u001b[43mnumpy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfromfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    848\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    849\u001b[39m         \u001b[38;5;66;03m# This is not a real file. We have to read it the\u001b[39;00m\n\u001b[32m    850\u001b[39m         \u001b[38;5;66;03m# memory-intensive way.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    858\u001b[39m         \u001b[38;5;66;03m# not correctly instantiate zero-width string dtypes; see\u001b[39;00m\n\u001b[32m    859\u001b[39m         \u001b[38;5;66;03m# https://github.com/numpy/numpy/pull/6430\u001b[39;00m\n\u001b[32m    860\u001b[39m         array = numpy.ndarray(count, dtype=dtype)\n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 18.3 GiB for an array with shape (2461918383,) and data type float64"
     ]
    }
   ],
   "source": [
    "NPY_PATH = os.path.join(OUTPUT_DIR, \"s3dis_full.npy\")\n",
    "\n",
    "NUM_POINTS = 1024   \n",
    "BATCH_SIZE = 2      \n",
    "NUM_WORKERS = 0     \n",
    "\n",
    "train_ds = S3DISAreaSplitDataset(NPY_PATH, split='train', num_points=NUM_POINTS)\n",
    "val_ds = S3DISAreaSplitDataset(NPY_PATH, split='val', num_points=NUM_POINTS)\n",
    "test_ds = S3DISAreaSplitDataset(NPY_PATH, split='test', num_points=NUM_POINTS)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS)\n",
    "val_loader = DataLoader(val_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "test_loader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS)\n",
    "\n",
    "print(\" DataLoader –≥–æ—Ç–æ–≤.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0153da28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def square_distance(src, dst):\n",
    "    B, N, _ = src.shape\n",
    "    _, M, _ = dst.shape\n",
    "    dist = -2 * torch.matmul(src, dst.transpose(2, 1))\n",
    "    dist += torch.sum(src ** 2, -1).view(B, N, 1)\n",
    "    dist += torch.sum(dst ** 2, -1).view(B, 1, M)\n",
    "    return dist\n",
    "\n",
    "def index_points(points, idx):\n",
    "    device = points.device\n",
    "    B = points.shape[0]\n",
    "    view_shape = list(idx.shape)\n",
    "    view_shape[1:] = [1] * (len(view_shape) - 1)\n",
    "    repeat_shape = list(idx.shape)\n",
    "    repeat_shape[0] = 1\n",
    "    batch_indices = torch.arange(B, dtype=torch.long, device=device).view(view_shape).repeat(repeat_shape)\n",
    "    new_points = points[batch_indices, idx, :]\n",
    "    return new_points\n",
    "\n",
    "def farthest_point_sample(xyz, npoint):\n",
    "    device = xyz.device\n",
    "    B, N, C = xyz.shape\n",
    "    centroids = torch.zeros(B, npoint, dtype=torch.long, device=device)\n",
    "    distance = torch.ones(B, N, device=device) * 1e10\n",
    "    farthest = torch.randint(0, N, (B,), dtype=torch.long, device=device)\n",
    "    batch_indices = torch.arange(B, dtype=torch.long, device=device)\n",
    "    for i in range(npoint):\n",
    "        centroids[:, i] = farthest\n",
    "        centroid = xyz[batch_indices, farthest, :].view(B, 1, 3)\n",
    "        dist = torch.sum((xyz - centroid) ** 2, -1)\n",
    "        mask = dist < distance\n",
    "        distance[mask] = dist[mask]\n",
    "        farthest = torch.max(distance, -1)[1]\n",
    "    return centroids\n",
    "\n",
    "def query_ball_point(radius, nsample, xyz, new_xyz):\n",
    "    device = xyz.device\n",
    "    B, N, _ = xyz.shape\n",
    "    _, S, _ = new_xyz.shape\n",
    "    group_idx = torch.arange(N, dtype=torch.long).to(device).view(1, 1, N).repeat([B, S, 1])\n",
    "    sqrdists = square_distance(new_xyz, xyz)\n",
    "    group_idx[sqrdists > radius ** 2] = N\n",
    "    group_idx = group_idx.sort(dim=-1)[0][:, :, :nsample]\n",
    "    group_first = group_idx[:, :, 0].view(B, S, 1).repeat([1, 1, nsample])\n",
    "    mask = group_idx == N\n",
    "    group_idx[mask] = group_first[mask]\n",
    "    return group_idx\n",
    "\n",
    "def sample_and_group(npoint, radius, nsample, xyz, points):\n",
    "    B, N, C = xyz.shape\n",
    "    S = npoint\n",
    "    fps_idx = farthest_point_sample(xyz, npoint)\n",
    "    new_xyz = index_points(xyz, fps_idx)\n",
    "    idx = query_ball_point(radius, nsample, xyz, new_xyz)\n",
    "    grouped_xyz = index_points(xyz, idx)\n",
    "    grouped_xyz_norm = grouped_xyz - new_xyz.view(B, S, 1, 3)\n",
    "    if points is not None:\n",
    "        grouped_points = index_points(points, idx)\n",
    "        new_points = torch.cat([grouped_xyz_norm, grouped_points], dim=-1)\n",
    "    else:\n",
    "        new_points = grouped_xyz_norm\n",
    "    return new_xyz, new_points\n",
    "\n",
    "class PointNetSetAbstraction(nn.Module):\n",
    "    def __init__(self, npoint, radius, nsample, in_channel, mlp, group_all=False):\n",
    "        super().__init__()\n",
    "        self.npoint = npoint\n",
    "        self.radius = radius\n",
    "        self.nsample = nsample\n",
    "        self.mlp_convs = nn.ModuleList()\n",
    "        self.mlp_bns = nn.ModuleList()\n",
    "        last_channel = in_channel\n",
    "        for out_channel in mlp:\n",
    "            self.mlp_convs.append(nn.Conv2d(last_channel, out_channel, 1))\n",
    "            self.mlp_bns.append(nn.BatchNorm2d(out_channel))\n",
    "            last_channel = out_channel\n",
    "        self.group_all = group_all\n",
    "\n",
    "    def forward(self, xyz, points):\n",
    "        if self.group_all:\n",
    "            new_xyz = xyz.mean(dim=1, keepdim=True)\n",
    "            grouped_points = points.unsqueeze(1)\n",
    "            grouped_xyz = xyz.unsqueeze(1) - new_xyz.unsqueeze(2)\n",
    "            if points is not None:\n",
    "                new_points = torch.cat([grouped_xyz, grouped_points], dim=-1)\n",
    "            else:\n",
    "                new_points = grouped_xyz\n",
    "        else:\n",
    "            new_xyz, new_points = sample_and_group(self.npoint, self.radius, self.nsample, xyz, points)\n",
    "\n",
    "        new_points = new_points.permute(0, 3, 2, 1)\n",
    "        for i, conv in enumerate(self.mlp_convs):\n",
    "            bn = self.mlp_bns[i]\n",
    "            new_points = F.relu(bn(conv(new_points)))\n",
    "        new_points = torch.max(new_points, 2)[0]\n",
    "        new_points = new_points.permute(0, 2, 1)\n",
    "        return new_xyz, new_points\n",
    "\n",
    "class PointNetFeaturePropagation(nn.Module):\n",
    "    def __init__(self, in_channel, mlp):\n",
    "        super().__init__()\n",
    "        self.mlp_convs = nn.ModuleList()\n",
    "        self.mlp_bns = nn.ModuleList()\n",
    "        last_channel = in_channel\n",
    "        for out_channel in mlp:\n",
    "            self.mlp_convs.append(nn.Conv1d(last_channel, out_channel, 1))\n",
    "            self.mlp_bns.append(nn.BatchNorm1d(out_channel))\n",
    "            last_channel = out_channel\n",
    "\n",
    "    def forward(self, xyz1, xyz2, points1, points2):\n",
    "        B, N, _ = xyz1.shape\n",
    "        _, S, _ = xyz2.shape\n",
    "\n",
    "        if S == 1:\n",
    "            interpolated_points = points2.repeat(1, N, 1)\n",
    "        else:\n",
    "            dists = square_distance(xyz1, xyz2)\n",
    "            dists, idx = dists.sort(dim=-1)\n",
    "            dists, idx = dists[:, :, :3], idx[:, :, :3]\n",
    "            dist_recip = 1.0 / (dists + 1e-8)\n",
    "            norm = torch.sum(dist_recip, dim=2, keepdim=True)\n",
    "            weight = dist_recip / norm\n",
    "            interpolated_points = torch.sum(index_points(points2, idx) * weight.unsqueeze(-1), dim=2)\n",
    "\n",
    "        if points1 is not None:\n",
    "            new_points = torch.cat([points1, interpolated_points], dim=-1)\n",
    "        else:\n",
    "            new_points = interpolated_points\n",
    "\n",
    "        new_points = new_points.permute(0, 2, 1)\n",
    "        for i, conv in enumerate(self.mlp_convs):\n",
    "            bn = self.mlp_bns[i]\n",
    "            new_points = F.relu(bn(conv(new_points)))\n",
    "        return new_points.permute(0, 2, 1)\n",
    "\n",
    "class PointNet2Seg(nn.Module):\n",
    "    def __init__(self, num_classes=14): \n",
    "        super().__init__()\n",
    "        self.sa1 = PointNetSetAbstraction(512, 0.2, 32, 6, [32, 32, 64])\n",
    "        self.sa2 = PointNetSetAbstraction(128, 0.4, 64, 64 + 3, [64, 64, 128])\n",
    "        self.sa3 = PointNetSetAbstraction(None, None, None, 128 + 3, [128, 256, 512], group_all=True)\n",
    "\n",
    "        self.fp3 = PointNetFeaturePropagation(512 + 128, [256, 256])\n",
    "        self.fp2 = PointNetFeaturePropagation(256 + 64, [256, 128])\n",
    "        self.fp1 = PointNetFeaturePropagation(128 + 6, [128, 128, 128])\n",
    "\n",
    "        self.conv1 = nn.Conv1d(128, 128, 1)\n",
    "        self.bn1 = nn.BatchNorm1d(128)\n",
    "        self.drop1 = nn.Dropout(0.5)\n",
    "        self.conv2 = nn.Conv1d(128, num_classes, 1)\n",
    "\n",
    "    def forward(self, xyz):\n",
    "        l0_xyz = xyz[:, :, :3]\n",
    "        l0_points = xyz[:, :, 3:]\n",
    "\n",
    "        l1_xyz, l1_points = self.sa1(l0_xyz, l0_points)\n",
    "        l2_xyz, l2_points = self.sa2(l1_xyz, l1_points)\n",
    "        l3_xyz, l3_points = self.sa3(l2_xyz, l2_points)\n",
    "\n",
    "        l2_points = self.fp3(l2_xyz, l3_xyz, l2_points, l3_points)\n",
    "        l1_points = self.fp2(l1_xyz, l2_xyz, l1_points, l2_points)\n",
    "        l0_points = self.fp1(l0_xyz, l1_xyz, l0_points, l1_points)\n",
    "\n",
    "        x = l0_points.permute(0, 2, 1)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.drop1(x)\n",
    "        x = self.conv2(x)\n",
    "        return x.permute(0, 2, 1)  # (B, N, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f887086",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"–ò—Å–ø–æ–ª—å–∑—É–µ–º–æ–µ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {device}\")\n",
    "\n",
    "model = PointNet2Seg(num_classes=NUM_CLASSES).to(device)\n",
    "print(\"–ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ –Ω–∞\", next(model.parameters()).device)\n",
    "\n",
    "train_labels = train_ds.points[:, 6].astype(int)\n",
    "class_counts = np.bincount(train_labels, minlength=NUM_CLASSES)\n",
    "class_weights = 1.0 / (class_counts + 1e-8)\n",
    "class_weights = torch.from_numpy(class_weights).float().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma=0.5)\n",
    "\n",
    "def compute_metrics(pred, target, num_classes=NUM_CLASSES):\n",
    "    pred = pred.view(-1)\n",
    "    target = target.view(-1)\n",
    "    cm = confusion_matrix(target.cpu().numpy(), pred.cpu().numpy(), labels=np.arange(num_classes))\n",
    "    oa = np.diag(cm).sum() / cm.sum()\n",
    "    iou = np.diag(cm) / (cm.sum(axis=1) + cm.sum(axis=0) - np.diag(cm) + 1e-6)\n",
    "    miou = np.nanmean(iou)\n",
    "    return oa, miou\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss, all_preds, all_targets = 0.0, [], []\n",
    "    with torch.no_grad():\n",
    "        for pts, lbl in loader:\n",
    "            pts, lbl = pts.to(device), lbl.to(device)\n",
    "            logits = model(pts)\n",
    "            loss = criterion(logits.permute(0, 2, 1), lbl)\n",
    "            total_loss += loss.item()\n",
    "            all_preds.append(logits.argmax(-1))\n",
    "            all_targets.append(lbl)\n",
    "    avg_loss = total_loss / len(loader)\n",
    "    preds = torch.cat(all_preds)\n",
    "    targets = torch.cat(all_targets)\n",
    "    oa, miou = compute_metrics(preds, targets)\n",
    "    return avg_loss, oa, miou\n",
    "\n",
    "EPOCHS = 10  # ‚Üê –¥–ª—è CPU –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ 5‚Äì10 —ç–ø–æ—Ö –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\n",
    "train_losses, val_losses, val_oas, val_mious = [], [], [], []\n",
    "best_miou = 0.0\n",
    "\n",
    "print(\" –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ...\")\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for pts, lbl in tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\", leave=False):\n",
    "        pts, lbl = pts.to(device), lbl.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        logits = model(pts)\n",
    "        loss = criterion(logits.permute(0, 2, 1), lbl)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    \n",
    "    avg_train_loss = epoch_loss / len(train_loader)\n",
    "    train_losses.append(avg_train_loss)\n",
    "    \n",
    "    val_loss, val_oa, val_miou = validate(model, val_loader, criterion, device)\n",
    "    val_losses.append(val_loss)\n",
    "    val_oas.append(val_oa)\n",
    "    val_mious.append(val_miou)\n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    print(f\"Epoch {epoch:2d} | Train Loss: {avg_train_loss:.4f} | \"\n",
    "          f\"Val Loss: {val_loss:.4f} | OA: {val_oa:.3f} | mIoU: {val_miou:.3f}\")\n",
    "    \n",
    "    if val_miou > best_miou:\n",
    "        best_miou = val_miou\n",
    "        torch.save(model.state_dict(), os.path.join(OUTPUT_DIR, \"best_pointnet2.pth\"))\n",
    "        print(\"   ‚Üí –°–æ—Ö—Ä–∞–Ω–µ–Ω–∞ –ª—É—á—à–∞—è –º–æ–¥–µ–ª—å!\")\n",
    "\n",
    "print(\" –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349b456f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(train_losses, label='Train Loss')\n",
    "plt.plot(val_losses, label='Val Loss')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Loss'); plt.legend(); plt.title('Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(val_oas, label='OA')\n",
    "plt.plot(val_mious, label='mIoU')\n",
    "plt.xlabel('Epoch'); plt.ylabel('Accuracy'); plt.legend(); plt.title('Metrics')\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(OUTPUT_DIR, \"training_curves.png\"), dpi=150)\n",
    "plt.show()\n",
    "\n",
    "model.load_state_dict(torch.load(os.path.join(OUTPUT_DIR, \"best_pointnet2.pth\"), weights_only=True))\n",
    "test_loss, test_oa, test_miou = validate(test_loader)\n",
    "print(f\"\\n –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –Ω–∞ TEST (Area_6):\\n  OA = {test_oa:.4f}\\n  mIoU = {test_miou:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7353a776",
   "metadata": {},
   "outputs": [],
   "source": [
    "1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "labs",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
